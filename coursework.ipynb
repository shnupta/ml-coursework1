{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58a3d686-9d4f-4755-96fe-51b0600103a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Coursework 1\n",
    "In this assignment, you will implement a decision tree algorithm and use it to determine one of the indoor locations based on WIFI signal strengths collected from a mobile phone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74570545-9f9f-4e19-a2df-afafc43f9cac",
   "metadata": {},
   "source": [
    "## Step 1: Loading data\n",
    "You can load the datasets from the files `wifi_db/clean_dataset.txt` and `wifi_db/noise_dataset.txt`. They contain a 2000x8 array.\n",
    "\n",
    "This array represents a dataset of 2000 samples. Each sample is composed of 7 wifi signal strengths while the last column indicates the room number in which the user is standing (i.e. the label of the sample). **All the features in the dataset are continuous _except_ the room number.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b9a6f15e-d9d9-463d-af41-99cd597bf715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import numpy as np\n",
    "from numpy.random import default_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "64dbdee0-fb28-483c-a1c3-e36930d6631a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-64. -56. -61. ... -82. -81.   1.]\n",
      " [-68. -57. -61. ... -85. -85.   1.]\n",
      " [-63. -60. -60. ... -85. -84.   1.]\n",
      " ...\n",
      " [-62. -59. -46. ... -87. -88.   4.]\n",
      " [-62. -58. -52. ... -90. -85.   4.]\n",
      " [-59. -50. -45. ... -88. -87.   4.]]\n",
      "[[-59. -53. -51. ... -79. -87.   4.]\n",
      " [-66. -53. -59. ... -81. -79.   1.]\n",
      " [-41. -57. -63. ... -66. -65.   2.]\n",
      " ...\n",
      " [-57. -54. -56. ... -79. -82.   1.]\n",
      " [-56. -52. -50. ... -85. -88.   3.]\n",
      " [-46. -54. -47. ... -80. -73.   3.]]\n"
     ]
    }
   ],
   "source": [
    "# Load in the datasets\n",
    "clean_dataset = np.loadtxt('wifi_db/clean_dataset.txt')\n",
    "noisy_dataset = np.loadtxt('wifi_db/noisy_dataset.txt')\n",
    "\n",
    "print(clean_dataset)\n",
    "print(noisy_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c5a712-26be-4ad7-a602-53cf5acdf5bc",
   "metadata": {},
   "source": [
    "## Step 2: Creating Decision Trees\n",
    "To create the decision tree, you will write a recursive function called `decision_tree_learning()`, that takes as arguments a matrix containing the dataset and a depth variable (which is used to compute the maximal depth of the tree, for plotting purposes for instance). The label of the training dataset is assumed to be the last column of the matrix.\n",
    "\n",
    "See the psuedo-code for the algorithm below.\n",
    "```\n",
    "1:  procedure DECISION_TREE_LEARNING(training_dataset, depth)\n",
    "2:    if all samples have the same label then\n",
    "3:      return (a leaf node with this value, depth)\n",
    "4:    else\n",
    "5:      split ← FIND_SPLIT(training dataset)\n",
    "6:      node ← a new decision tree with root as split value\n",
    "7:      l_branch, l_depth ← DECISION_TREE_LEARNING(l_dataset, depth+1)\n",
    "8:      r_branch, r_depth ← DECISION_TREE_LEARNING(r_dataset, depth+1)\n",
    "9:      return (node, max(l_depth, r_depth))\n",
    "10:   end if\n",
    "11: end procedure\n",
    "```\n",
    "\n",
    "The function `FIND_SPLIT` chooses the attribute and the value that results in the highest information gain.\n",
    "\n",
    "An efficient method for finding good split points is to sort the values of the attribute, and then consider only split points that are **between two examples in sorted order**, while keeping track of the running totals of examples of each class for each side of the split point.\n",
    "\n",
    "To evaluate the information gain, suppose that the training dataset S_all has K different labels. We can define two subsets (S_left and S_right) of the dataset depending on the splitting rule and for each dataset and subset, we can compute the distribution (or probability) of each label. For instance, {p1, p2, ..., pk} where pk is the number of samples with the label k divided by the total number of samples from the initial dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4ea06b80-53be-409a-a553-9dbb1c7cfede",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Class used to represent decision nodes in a decision tree.\n",
    "\n",
    "Members:\n",
    "- value     : the value on which to split\n",
    "- attribute : the attribute on which to split\n",
    "- left      : the left sub-tree\n",
    "- right     : the right sub-tree\n",
    "\n",
    "Methods:\n",
    "- is_leaf : returns a boolean indicating whether or not this is a leaf node\n",
    "\"\"\"\n",
    "class Node:\n",
    "    def __init__(self, value = None, attribute = None):\n",
    "        self.value = value\n",
    "        self.attribute = attribute\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.label = None\n",
    "    \n",
    "    def is_leaf(self):\n",
    "        return self.left == None and self.right == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Chooses the attribute and the value that results in the highest information gain\n",
    "\n",
    "Arguments:\n",
    "- training_dataset (last column is the label)\n",
    "\n",
    "Returns:\n",
    "- tuple : Returns a tuple of (split_attribute, split_value, left_dataset, right_dataset)\n",
    "          - split_attribute: The column index of the value that was split on\n",
    "          - split_value: The value used to split the dataset into left and right\n",
    "          - left_dataset: All elements have a `split_attribute` value < `split_value`\n",
    "          - right_dataset: All elements have a `split_attribute` value >= `split_value`\n",
    "\"\"\"\n",
    "def find_split(training_dataset):\n",
    "    best_split = (0, None)\n",
    "\n",
    "    for attribute in range(training_dataset.shape[1] - 1):\n",
    "        # Sort the rows by the current attribute's values\n",
    "        sorted_attribute_indices = np.argsort(training_dataset, axis=0)[:, attribute]\n",
    "        sorted_by_attribute = training_dataset[sorted_attribute_indices, :]\n",
    "        # Get the index of each point where the value changes\n",
    "        _, split_points = np.unique(sorted_by_attribute[:, attribute], return_index=True)\n",
    "        for split_point in split_points:\n",
    "            # Find the information gained from splitting at this point\n",
    "            left = sorted_by_attribute[:split_point, :]\n",
    "            right = sorted_by_attribute[split_point:, :]\n",
    "            info_gain = information_gain(training_dataset, left, right)\n",
    "            split_value = sorted_by_attribute[split_point, attribute]\n",
    "            # Replace best_split if more information is gained by splitting here\n",
    "            best_split = max(best_split, (info_gain, (attribute, split_value, left, right)), key=lambda x: x[0])\n",
    "\n",
    "    return best_split[1]\n",
    "\n",
    "# Returns the information gain when the dataset `data` is split into two distinct subsets `left` and `right`\n",
    "def information_gain(data, left, right):\n",
    "    return entropy(data) - remainder(left, right)\n",
    "\n",
    "# Returns the information entropy of `dataset`\n",
    "def entropy(dataset):\n",
    "    _, counts = np.unique(dataset[:, -1], return_counts=True)\n",
    "    probabilities = counts / counts.sum()\n",
    "    return -(probabilities * np.log2(probabilities)).sum()\n",
    "\n",
    "# Returns the (weighted) average entropy of the two subsets `left` and `right`\n",
    "def remainder(left, right):\n",
    "    proportion_left = len(left) / (len(left) + len(right))\n",
    "    return proportion_left * entropy(left) + (1 - proportion_left) * entropy(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "85add714-c5a9-4b27-bd29-3b043a94e303",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Constructs a decision tree by learning from training_dataset.\n",
    "\n",
    "Arguments:\n",
    "- training_dataset (last column is the label)\n",
    "- depth\n",
    "\n",
    "Returns:\n",
    "- A decision tree in the form of a root Node and subsequent left and right nodes\n",
    "\"\"\"\n",
    "def decision_tree_learning(training_dataset, depth):\n",
    "    unique_labels = np.unique(training_dataset[:,-1])\n",
    "    # If all samples have the same label return a leaf node with this label\n",
    "    if (len(unique_labels) == 1):\n",
    "        node = Node()\n",
    "        node.label = unique_labels[0]\n",
    "        return (node, depth)\n",
    "    else:\n",
    "        # Find the optimum split attribute and value and the corresponding split subsets\n",
    "        split_attribute, split_value, left_dataset, right_dataset = find_split(training_dataset)\n",
    "        # Create a new decision tree with this split value and attribute\n",
    "        node = Node(split_value, split_attribute)\n",
    "        # Construct the rest of the decision tree\n",
    "        left_branch, left_depth = decision_tree_learning(left_dataset, depth + 1)\n",
    "        right_branch, right_depth = decision_tree_learning(right_dataset, depth + 1)\n",
    "        # Assign these branches to the root node\n",
    "        node.left = left_branch\n",
    "        node.right = right_branch\n",
    "        \n",
    "        return (node, max(left_depth, right_depth))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0e85b1-5388-45d0-b674-73c39ba12c4a",
   "metadata": {},
   "source": [
    "## Step 3: Evaluation\n",
    "Evaluate your decision tree using a 10-fold cross validation on both the clean and noisy datasets. You should expect that slightly different trees will be created with each fold, since the training data that you use each time will be slightly different. Use your resulting decision trees to classify your data in your test sets.\n",
    "\n",
    "Implement an evaluation function that takes a trained tree and a test dataset: `evaluate(test_db, trained_tree)` and that returns the accuracy of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Decides a label for this set of features using tree\n",
    "\n",
    "Arguments:\n",
    "- features : a single example of training data\n",
    "- tree     : decision tree\n",
    "\"\"\"\n",
    "def decide_label(features, tree):\n",
    "    if (tree.is_leaf()):\n",
    "        return tree.label\n",
    "    \n",
    "    if (features[tree.attribute] < tree.value):\n",
    "        return decide_label(features, tree.left)\n",
    "    else:\n",
    "        return decide_label(features, tree.right)\n",
    "\n",
    "def predict(test_db, trained_tree):\n",
    "    predictions = np.zeros(len(test_db))\n",
    "    for i, row in enumerate(test_db):\n",
    "        predictions[i] = decide_label(row[:-1], trained_tree)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Evaluates the performance of trained_tree on test_db\n",
    "\n",
    "Arguments:\n",
    "- test_db      : data used for testing (last column is label)\n",
    "- trained_tree : trained decision tree\n",
    "\n",
    "Returns:\n",
    "- accuracy (float)\n",
    "\"\"\"\n",
    "def evaluate(test_db, trained_tree):\n",
    "    predictions = predict(test_db, trained_tree)\n",
    "    return np.sum(test_db[:, -1] == predictions) / len(test_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffled_indices = default_rng().permutation(len(clean_dataset))\n",
    "# shuffled_dataset = clean_dataset[shuffled_indices, :]\n",
    "# tree, depth = decision_tree_learning(shuffled_dataset[:1800, :], 0)\n",
    "# print(evaluate(shuffled_dataset[1800:, :], tree))\n",
    "\n",
    "def train_test_k_fold(n_instances, n_folds=10):\n",
    "    shuffled_indices = default_rng().permutation(n_instances)\n",
    "    split_indices = np.array_split(shuffled_indices, n_folds)\n",
    "    folds = []\n",
    "\n",
    "    for k in range(n_folds):\n",
    "        test_indices = split_indices[k] \n",
    "        train_indices = np.concatenate(split_indices[:k] + split_indices[k+1:])\n",
    "        folds.append([train_indices, test_indices])\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Perform k_fold cross-validation and return the predictions and labels\n",
    "\"\"\"\n",
    "def cross_validation(dataset):\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for _, (train_indices, test_indices) in enumerate(train_test_k_fold(len(dataset), 10)):\n",
    "        train_set = dataset[train_indices]\n",
    "        test_set = dataset[test_indices]\n",
    "        tree, _ = decision_tree_learning(train_set, 0)\n",
    "\n",
    "        predictions.append(predict(test_set, tree))\n",
    "        labels.append(test_set[:, -1])\n",
    "\n",
    "    return predictions, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute the confusion matrix.\n",
    "    \n",
    "Argumentss:\n",
    "- y_gold (np.ndarray): the correct ground truth/gold standard labels\n",
    "- y_prediction (np.ndarray): the predicted labels\n",
    "- class_labels (np.ndarray): a list of unique class labels. \n",
    "                        Defaults to the union of y_gold and y_prediction.\n",
    "\n",
    "Returns:\n",
    "- np.array : shape (C, C), where C is the number of classes. \n",
    "            Rows are ground truth per class, columns are predictions\n",
    "\"\"\"\n",
    "def confusion_matrix(y_gold, y_prediction, class_labels):\n",
    "  \n",
    "    confusion = np.zeros((len(class_labels), len(class_labels)))\n",
    "\n",
    "    # for each correct class (row), \n",
    "    # compute how many instances are predicted for each class (columns)\n",
    "    for i, row_label in enumerate(class_labels):\n",
    "      ground_indices = y_gold == row_label\n",
    "      label_predictions = y_prediction[ground_indices]\n",
    "      labels, prediction_counts = np.unique(label_predictions, return_counts=True)\n",
    "      \n",
    "      label_dict = dict(zip(labels, prediction_counts))\n",
    "\n",
    "      for j, column_label in enumerate(class_labels):\n",
    "        confusion[i, j] = label_dict.get(column_label, 0)\n",
    "\n",
    "\n",
    "    return confusion\n",
    "\n",
    "\n",
    "def avg_confusion_matrix(predictions, labels, class_labels=None):\n",
    "    if not class_labels:\n",
    "        class_labels = np.unique(np.concatenate((np.vstack(predictions), np.vstack(labels)))) \n",
    "    totals = np.zeros((len(class_labels), len(class_labels)))\n",
    "    for i in range(len(predictions)):\n",
    "      totals += confusion_matrix(labels[i], predictions[i], class_labels)\n",
    "\n",
    "    return totals / len(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute the accuracy given the confusion matrix\n",
    "\n",
    "Args:\n",
    "- confusion (np.ndarray): shape (C, C), where C is the number of classes. \n",
    "            Rows are ground truth per class, columns are predictions\n",
    "\n",
    "Returns:\n",
    "- float : the accuracy\n",
    "\"\"\"    \n",
    "def accuracy_from_confusion(confusion):\n",
    "    if np.sum(confusion) > 0:\n",
    "        return np.sum(np.diag(confusion)) / np.sum(confusion)\n",
    "    else:\n",
    "        return 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute the precision score per class given the ground truth and predictions\n",
    "    \n",
    "Also return the macro-averaged precision across classes.\n",
    "    \n",
    "Args:\n",
    "- y_gold (np.ndarray): the correct ground truth/gold standard labels\n",
    "- y_prediction (np.ndarray): the predicted labels\n",
    "\n",
    "Returns:\n",
    "- tuple: returns a tuple (precisions, macro_precision) where\n",
    "    - precisions is a np.ndarray of shape (C,), where each element is the \n",
    "        precision for class c\n",
    "    - macro-precision is macro-averaged precision (a float) \n",
    "\"\"\"\n",
    "def precision(confusion):\n",
    "\n",
    "    # Compute the precision per class\n",
    "    p = np.zeros(len(confusion))\n",
    "\n",
    "    for i, _ in enumerate(confusion):\n",
    "        if np.sum(confusion[:, i]) > 0:\n",
    "            p[i] = confusion[i, i] / np.sum(confusion[:,i])\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute the recall score per class given the ground truth and predictions\n",
    "    \n",
    "Also return the macro-averaged recall across classes.\n",
    "    \n",
    "Args:\n",
    "- y_gold (np.ndarray): the correct ground truth/gold standard labels\n",
    "- y_prediction (np.ndarray): the predicted labels\n",
    "\n",
    "Returns:\n",
    "- tuple: returns a tuple (recalls, macro_recall) where\n",
    "    - recalls is a np.ndarray of shape (C,), where each element is the \n",
    "        recall for class c\n",
    "    - macro-recall is macro-averaged recall (a float) \n",
    "\"\"\"\n",
    "def recall(confusion):\n",
    "    # Compute the recall per class\n",
    "    r = np.zeros(len(confusion))\n",
    "\n",
    "    for label, _ in enumerate(confusion):\n",
    "        if np.sum(confusion[label, :]) > 0:\n",
    "            r[label] = confusion[label, label] / np.sum(confusion[label])\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(confusion):\n",
    "    recalls, precisions = recall(confusion), precision(confusion)\n",
    "\n",
    "    f = np.zeros(len(confusion))\n",
    "    for i, (r, p) in enumerate(zip(recalls, precisions)):\n",
    "        f[i] = 2 * r * p / (r + p)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, labels = cross_validation(noisy_dataset)\n",
    "confusion = avg_confusion_matrix(predictions, labels)\n",
    "print(confusion)\n",
    "print(accuracy_from_confusion(confusion))\n",
    "print(recall(confusion))\n",
    "print(precision(confusion))\n",
    "print(f1(confusion))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
